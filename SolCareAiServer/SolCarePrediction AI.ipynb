{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# MySQL 연결\n",
    "connection = pymysql.connect(\n",
    "    host='database-1.cbcw28i2we7h.us-east-2.rds.amazonaws.com',\n",
    "    user='kj',\n",
    "    password='1234',\n",
    "    database='nahonlab',\n",
    "    charset='utf8mb4'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# 데이터 생성 설정\n",
    "num_users = 30  # user_id 3부터 32까지\n",
    "start_date = datetime(2024, 11, 1)\n",
    "end_date = datetime(2024, 11, 30)\n",
    "\n",
    "# 사용자별 초기 값 설정\n",
    "initial_metrics = {\n",
    "    user_id: {\n",
    "        \"height\": random.randint(160, 190),  # 고정된 키 값\n",
    "        \"weight\": random.uniform(50, 80),\n",
    "        \"fat_percent\": random.uniform(15, 30),\n",
    "        \"muscle_mass\": random.uniform(25, 40),\n",
    "    }\n",
    "    for user_id in range(3, 33)  # user_id 3부터 32까지\n",
    "}\n",
    "\n",
    "# 기본 값 생성 함수\n",
    "def generate_metrics(user_id, prev_weight, prev_fat_percent, prev_muscle_mass):\n",
    "    calories_intake = random.randint(1800, 3500)  # 섭취 칼로리\n",
    "    calories_burned = random.randint(500, 1000)   # 소모 칼로리\n",
    "\n",
    "    # 체중 변화: 섭취 > 소모 -> 증가, 섭취 < 소모 -> 감소\n",
    "    calorie_diff = calories_intake - calories_burned\n",
    "    weight_change = calorie_diff / 7000  # 1kg = 약 7000kcal\n",
    "    new_weight = max(45, prev_weight + weight_change)  # 체중은 최소 45kg\n",
    "\n",
    "    # 체지방률 변화: 섭취 > 소모 -> 증가, 운동량 높으면 감소\n",
    "    fat_change = 0.2 if calorie_diff > 500 else (-0.1 if calories_burned > 800 else 0)\n",
    "    new_fat_percent = max(5, min(40, prev_fat_percent + fat_change))  # 체지방률 5~40% 제한\n",
    "\n",
    "    # 근육량 변화: 소모 칼로리가 높으면 증가, 섭취만 높으면 유지\n",
    "    muscle_change = 0.1 if calories_burned > 700 else (-0.05 if calorie_diff > 0 else 0.02)\n",
    "    new_muscle_mass = max(20, prev_muscle_mass + muscle_change)  # 근육량 최소 20kg\n",
    "\n",
    "    return new_weight, new_fat_percent, new_muscle_mass, calories_burned, calories_intake\n",
    "\n",
    "# 데이터 생성 및 삽입\n",
    "for user_id in range(3, 33):\n",
    "    user_metrics = initial_metrics[user_id]\n",
    "    prev_weight = user_metrics[\"weight\"]\n",
    "    prev_fat_percent = user_metrics[\"fat_percent\"]\n",
    "    prev_muscle_mass = user_metrics[\"muscle_mass\"]\n",
    "    height = user_metrics[\"height\"]  # 고정된 키 값\n",
    "\n",
    "    date = start_date\n",
    "    while date <= end_date:\n",
    "        # 새로운 데이터 생성\n",
    "        new_weight, new_fat_percent, new_muscle_mass, calories_burned, calories_intake = generate_metrics(\n",
    "            user_id, prev_weight, prev_fat_percent, prev_muscle_mass\n",
    "        )\n",
    "\n",
    "        # 데이터 삽입\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO user_body_metrics (user_id, record_date, height, weight, fat_percent, muscle_mass, calories_burned, calories_intake)\n",
    "            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\n",
    "            \"\"\",\n",
    "            (\n",
    "                user_id,\n",
    "                date.strftime('%Y-%m-%d'),\n",
    "                height,  # 고정된 키 값 사용\n",
    "                round(new_weight, 2),\n",
    "                round(new_fat_percent, 2),\n",
    "                round(new_muscle_mass, 2),\n",
    "                calories_burned,\n",
    "                calories_intake\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # 이전 값을 업데이트\n",
    "        prev_weight = new_weight\n",
    "        prev_fat_percent = new_fat_percent\n",
    "        prev_muscle_mass = new_muscle_mass\n",
    "\n",
    "        # 다음 날짜로 이동\n",
    "        date += timedelta(days=1)\n",
    "\n",
    "# 데이터베이스 커밋\n",
    "connection.commit()\n",
    "\n",
    "# 데이터 가져오기 및 상관관계 분석\n",
    "query = \"\"\"\n",
    "SELECT weight, record_date, fat_percent, muscle_mass, calories_burned, calories_intake\n",
    "FROM user_body_metrics\n",
    "\"\"\"\n",
    "data = pd.read_sql(query, connection)\n",
    "\n",
    "# 상관관계 계산 및 시각화\n",
    "correlation_matrix = data.corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix of User Body Metrics\")\n",
    "plt.show()\n",
    "\n",
    "# 연결 닫기\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data generation, insertion, and correlation analysis complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 19:46:55.974226: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-12 19:46:55.974338: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-12 19:46:56.006078: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-12 19:46:56.073776: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-12 19:46:57.168063: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/tmp/ipykernel_5708/1913586348.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, connection)\n",
      "2024-12-12 19:47:02.483758: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.605906: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.606383: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.607953: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.608223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.608370: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.691223: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.691508: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.691672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-12 19:47:02.691792: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4785 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 19:47:05.170021: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-12-12 19:47:05.679427: I external/local_xla/xla/service/service.cc:168] XLA service 0x7e898c144e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-12-12 19:47:05.679450: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2024-12-12 19:47:05.691488: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734000425.874222    5918 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/36 [======================>.......] - ETA: 0s - loss: 0.1305"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import joblib\n",
    "\n",
    "# MySQL 데이터베이스 연결 설정\n",
    "connection = pymysql.connect(\n",
    "    host='database-1.cbcw28i2we7h.us-east-2.rds.amazonaws.com',\n",
    "    user='kj',\n",
    "    password='1234',\n",
    "    database='nahonlab',\n",
    "    charset='utf8mb4'\n",
    ")\n",
    "\n",
    "# 데이터 불러오기\n",
    "query = \"\"\"\n",
    "SELECT user_id, record_date, weight, fat_percent, muscle_mass, calories_burned, calories_intake\n",
    "FROM user_body_metrics\n",
    "\"\"\"\n",
    "data = pd.read_sql(query, connection)\n",
    "connection.close()\n",
    "\n",
    "# 날짜 형식 변환 및 정렬\n",
    "data['record_date'] = pd.to_datetime(data['record_date'])\n",
    "data = data.sort_values(['user_id', 'record_date'])\n",
    "\n",
    "# 피처와 타깃 변수 정의\n",
    "features = data[['calories_burned', 'calories_intake']]\n",
    "targets = data[['weight', 'fat_percent', 'muscle_mass']]\n",
    "\n",
    "# 정규화\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_targets = MinMaxScaler()\n",
    "\n",
    "if not features.empty:\n",
    "    features_scaled = scaler_features.fit_transform(features)\n",
    "    targets_scaled = scaler_targets.fit_transform(targets)\n",
    "else:\n",
    "    raise ValueError(\"데이터셋이 비어있습니다. 학습할 데이터가 필요합니다.\")\n",
    "\n",
    "# 시계열 데이터 생성 함수\n",
    "def create_sequences(features, targets, time_steps=15):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - time_steps):\n",
    "        X.append(features[i:(i + time_steps)])\n",
    "        y.append(targets[i + time_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# 시퀀스 데이터 생성\n",
    "TIME_STEPS = 15\n",
    "X, y = create_sequences(features_scaled, targets_scaled, TIME_STEPS)\n",
    "\n",
    "# 학습 및 테스트 데이터 분리\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# 단일 모델 생성 및 학습\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, return_sequences=False, input_shape=input_shape))\n",
    "    model.add(Dense(3))  # 예측할 타깃 변수의 수\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "model = create_lstm_model((X_train.shape[1], X_train.shape[2]))\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=16, validation_split=0.2, shuffle=False)\n",
    "\n",
    "# 모델 저장\n",
    "model.save(\"global_model.h5\")\n",
    "joblib.dump(scaler_features, \"global_scaler_features.pkl\")\n",
    "joblib.dump(scaler_targets, \"global_scaler_targets.pkl\")\n",
    "\n",
    "print(\"전체 데이터를 사용하여 모델 학습 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 14:28:03.086151: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-13 14:28:03.086210: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-13 14:28:03.117520: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-13 14:28:03.183441: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-13 14:28:04.264303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-12-13 14:28:06.666329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.776852: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.777226: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.778104: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.778363: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.778584: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.866436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.866815: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.866938: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-13 14:28:06.867176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4756 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "/tmp/ipykernel_20014/3604748986.py:33: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(\"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 358ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-13 14:28:09.018749: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "User 8의 다음 20일 예측 결과:\n",
      "Day 1: 체중=75.69kg, 체지방률=25.52%, 근육량=34.97kg\n",
      "Day 2: 체중=73.49kg, 체지방률=25.54%, 근육량=34.84kg\n",
      "Day 3: 체중=72.49kg, 체지방률=25.72%, 근육량=34.92kg\n",
      "Day 4: 체중=71.98kg, 체지방률=25.81%, 근육량=34.96kg\n",
      "Day 5: 체중=71.46kg, 체지방률=25.90%, 근육량=34.99kg\n",
      "Day 6: 체중=71.01kg, 체지방률=25.99%, 근육량=35.02kg\n",
      "Day 7: 체중=71.05kg, 체지방률=26.00%, 근육량=35.02kg\n",
      "Day 8: 체중=70.41kg, 체지방률=26.11%, 근육량=35.04kg\n",
      "Day 9: 체중=68.98kg, 체지방률=26.34%, 근육량=35.09kg\n",
      "Day 10: 체중=68.72kg, 체지방률=26.41%, 근육량=35.10kg\n",
      "Day 11: 체중=70.38kg, 체지방률=26.16%, 근육량=35.04kg\n",
      "Day 12: 체중=71.49kg, 체지방률=25.96%, 근육량=34.98kg\n",
      "Day 13: 체중=70.39kg, 체지방률=26.10%, 근육량=35.00kg\n",
      "Day 14: 체중=70.07kg, 체지방률=26.16%, 근육량=35.02kg\n",
      "Day 15: 체중=69.66kg, 체지방률=26.22%, 근육량=35.03kg\n",
      "Day 16: 체중=70.22kg, 체지방률=26.16%, 근육량=35.02kg\n",
      "Day 17: 체중=70.56kg, 체지방률=26.09%, 근육량=35.00kg\n",
      "Day 18: 체중=70.77kg, 체지방률=26.05%, 근육량=34.99kg\n",
      "Day 19: 체중=70.89kg, 체지방률=26.03%, 근육량=34.99kg\n",
      "Day 20: 체중=70.96kg, 체지방률=26.01%, 근육량=34.98kg\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import tensorflow.keras.models as keras_models\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# 시계열 데이터의 길이 (시간 단계)\n",
    "TIME_STEPS = 15\n",
    "\n",
    "# 예측 함수\n",
    "def predict_for_user(user_id, predict_days=15):\n",
    "    # MySQL 데이터베이스 연결 설정\n",
    "    connection = pymysql.connect(\n",
    "        host='database-1.cbcw28i2we7h.us-east-2.rds.amazonaws.com',\n",
    "        user='kj',\n",
    "        password='1234',\n",
    "        database='nahonlab',\n",
    "        charset='utf8mb4'\n",
    "    )\n",
    "\n",
    "    # 저장된 모델 및 스케일러 로드\n",
    "    try:\n",
    "        model = keras_models.load_model(\"global_model.h5\")\n",
    "        scaler_features = joblib.load(\"global_scaler_features.pkl\")\n",
    "        scaler_targets = joblib.load(\"global_scaler_targets.pkl\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"저장된 글로벌 모델 또는 스케일러가 없습니다.\")\n",
    "        connection.close()  # 연결 종료\n",
    "        return\n",
    "\n",
    "    # 데이터 불러오기\n",
    "    try:\n",
    "        data = pd.read_sql(\"\"\"\n",
    "        SELECT user_id, record_date, weight, fat_percent, muscle_mass, calories_burned, calories_intake\n",
    "        FROM user_body_metrics\n",
    "        \"\"\", connection)\n",
    "    except Exception as e:\n",
    "        print(f\"데이터베이스 쿼리 실행 중 오류 발생: {e}\")\n",
    "        connection.close()  # 연결 종료\n",
    "        return\n",
    "\n",
    "    user_data = data[data['user_id'] == user_id].copy()\n",
    "    features = user_data[['calories_burned', 'calories_intake']]\n",
    "\n",
    "    if features.empty:\n",
    "        print(f\"User {user_id}에 대한 데이터가 없습니다.\")\n",
    "        connection.close()  # 연결 종료\n",
    "        return\n",
    "\n",
    "    features_scaled = scaler_features.transform(features)\n",
    "\n",
    "    if len(features_scaled) < TIME_STEPS:\n",
    "        print(f\"User {user_id}에 대한 충분한 데이터가 없어 예측을 수행할 수 없습니다.\")\n",
    "        connection.close()  # 연결 종료\n",
    "        return\n",
    "\n",
    "    last_15_days_features = features_scaled[-TIME_STEPS:]\n",
    "    current_sequence = last_15_days_features\n",
    "    predictions_scaled = []\n",
    "\n",
    "    for _ in range(predict_days):\n",
    "        next_pred_scaled = model.predict(current_sequence[np.newaxis, :, :])[0]\n",
    "        predictions_scaled.append(next_pred_scaled)\n",
    "        next_feature = np.array([next_pred_scaled[0], next_pred_scaled[1]])\n",
    "        current_sequence = np.vstack((current_sequence[1:], next_feature))\n",
    "\n",
    "    predictions = scaler_targets.inverse_transform(predictions_scaled)\n",
    "\n",
    "    # 연결 종료\n",
    "    connection.close()\n",
    "    return predictions\n",
    "\n",
    "# 예측 결과 출력 함수\n",
    "def display_predictions(user_id, predict_days=15):\n",
    "    predictions = predict_for_user(user_id, predict_days)\n",
    "    if predictions is not None:\n",
    "        print(f\"User {user_id}의 다음 {predict_days}일 예측 결과:\")\n",
    "        for day, pred in enumerate(predictions, 1):\n",
    "            print(f\"Day {day}: 체중={pred[0]:.2f}kg, 체지방률={pred[1]:.2f}%, 근육량={pred[2]:.2f}kg\")\n",
    "\n",
    "# 예시로 특정 사용자 예측 (예: 10일 예측)\n",
    "display_predictions(user_id=8, predict_days=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
